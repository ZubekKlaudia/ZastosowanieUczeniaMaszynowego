{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZubekKlaudia/ZastosowanieUczeniaMaszynowego/blob/main/Zastosowanie_g%C5%82%C4%99bokiego_uczenia_maszynowego_do_rozpoznawania_ras_ps%C3%B3w_poprawki_14_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObQouPHZZydi"
      },
      "source": [
        "#„Zastosowanie głębokiego uczenia maszynowego do rozpoznawania ras psów na podstawie zdjęć”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRjFoo9SPcP"
      },
      "source": [
        "Autor: Klaudia Zubek"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUF3QtoDHbuc"
      },
      "source": [
        "Import niezbędnych bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYk_s-HG8o1v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Model\n",
        "import joblib\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W32CoevHaATK"
      },
      "source": [
        "#Import zbioru danych Stanford Dog Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOYCzOrOtvgv"
      },
      "outputs": [],
      "source": [
        "# Instalacja biblioteki Kaggle, pobranie i rozpakowanie zbioru danych Stanford Dogs\n",
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset --unzip\n",
        "data_dir = './'\n",
        "image_directory = os.path.join(data_dir, './images/Images/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm6Nr2RvDDPr"
      },
      "source": [
        "#Eksploracja Danych (EDA - Exploratory Data Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q265AE4bHaGK"
      },
      "outputs": [],
      "source": [
        "# Policzenie klas oraz prezentacja przykładowych wyników\n",
        "classes = os.listdir(image_directory)\n",
        "\n",
        "print(f\"Liczba klas (ras psów): {len(classes)}\")\n",
        "print(\"Przykładowe klasy:\")\n",
        "print(classes[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiYQgPZ1D6gF"
      },
      "outputs": [],
      "source": [
        "# Policzenie przykładów w każdej klasie i wyświetlenie posortowanej tabeli\n",
        "class_counts = {folder: len(os.listdir(os.path.join('./images/Images/', folder))) for folder in os.listdir('./images/Images/')}\n",
        "\n",
        "class_counts_df = pd.DataFrame.from_dict(class_counts, orient='index', columns=['Liczba przykładów'])\n",
        "class_counts_df.index.name = 'Klasa'\n",
        "class_counts_df.reset_index(inplace=True)\n",
        "\n",
        "class_counts_df_sorted = class_counts_df.sort_values(by='Liczba przykładów', ascending=False)\n",
        "\n",
        "display(class_counts_df_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKB_DHyVFr_5"
      },
      "outputs": [],
      "source": [
        "# Obliczenie zakresu liczebności klas i wyświetlenie różnicę między największą a najmniejszą wartością\n",
        "max_count = class_counts_df_sorted['Liczba przykładów'].max()\n",
        "min_count = class_counts_df_sorted['Liczba przykładów'].min()\n",
        "range_count = max_count - min_count\n",
        "\n",
        "print(f\"Największa liczba przykładów: {max_count}\")\n",
        "print(f\"Najmniejsza liczba przykładów: {min_count}\")\n",
        "print(f\"Zakres liczebności klas (różnica): {range_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKYMww6aJjqw"
      },
      "source": [
        "#Wizualizacja obrazów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APze6l4uGL1q"
      },
      "outputs": [],
      "source": [
        "# Wyświetlenie obrazów z przykładowej klasy\n",
        "example_class = os.listdir(image_directory)[0]\n",
        "example_images = os.listdir(os.path.join(image_directory, example_class))[:5]\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, img_name in enumerate(example_images):\n",
        "    img_path = os.path.join(image_directory, example_class, img_name)\n",
        "    img = Image.open(img_path)\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(example_class,fontsize=7)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "houp-gOWHr5i"
      },
      "outputs": [],
      "source": [
        "# Wyświetlenie obrazów z przykładowych klas\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, cls in enumerate(classes[:9]):\n",
        "    img_name = random.choice(os.listdir(os.path.join(image_directory, cls)))\n",
        "    img_path = os.path.join(image_directory, cls, img_name)\n",
        "    img = Image.open(img_path)\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(cls, fontsize=8)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vNOv627Igoa"
      },
      "outputs": [],
      "source": [
        "# Wyświetlenie liczby uszkodzonych obrazów\n",
        "damaged_images = []\n",
        "for cls in classes:\n",
        "    for img_name in os.listdir(os.path.join(image_directory, cls)):\n",
        "        img_path = os.path.join(image_directory, cls, img_name)\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img.verify()\n",
        "        except:\n",
        "            damaged_images.append(img_path)\n",
        "\n",
        "print(f\"Liczba uszkodzonych obrazów: {len(damaged_images)}\")\n",
        "if damaged_images:\n",
        "    print(\"Przykładowe uszkodzone obrazy:\", damaged_images[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IsBDQmWIv6Z"
      },
      "source": [
        "#Przygotowanie danych do uczenia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcFNYXQ1ZlPl"
      },
      "outputs": [],
      "source": [
        "# Ustawienie ścieżek do danych\n",
        "train_data_folder = './data/train'\n",
        "validation_data_folder = './data/val'\n",
        "test_data_folder = './data/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjcwyawQt6xi"
      },
      "outputs": [],
      "source": [
        "# Utwórzenie katalogów i podział danych w odpowiedniej proporcji na zbior treningowy, walidacyjny i testowy\n",
        "os.makedirs(train_data_folder, exist_ok=True)\n",
        "os.makedirs(validation_data_folder, exist_ok=True)\n",
        "os.makedirs(test_data_folder, exist_ok=True)\n",
        "\n",
        "classes = os.listdir(image_directory)\n",
        "\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "#Pętla for iteruje przez wszystkie klasy\n",
        "for class_name in classes:\n",
        "    if class_name.startswith('.'):\n",
        "        continue\n",
        "    class_path = os.path.join(image_directory, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    #Następuje pobranie wszystkich obrazów w folderze danej klasy\n",
        "    images = os.listdir(class_path)\n",
        "\n",
        "    #Podział danych\n",
        "    train_images, val_test_images = train_test_split(images, test_size=(1 - train_ratio))\n",
        "    val_images, test_images = train_test_split(val_test_images, test_size=(test_ratio / (val_ratio + test_ratio)))\n",
        "\n",
        "    #Utworzenie katalogów\n",
        "    os.makedirs(os.path.join(train_data_folder, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(validation_data_folder, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_data_folder, class_name), exist_ok=True)\n",
        "\n",
        "    #Kopiowanie obrazów do odpowiednich katalogów\n",
        "    for image in train_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(train_data_folder, class_name, image))\n",
        "\n",
        "    for image in val_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(validation_data_folder, class_name, image))\n",
        "\n",
        "    for image in test_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(test_data_folder, class_name, image))\n",
        "\n",
        "print(\"Dane zostały podzielone na zbiory treningowy, walidacyjny i testowy.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg506_IIt8gY"
      },
      "outputs": [],
      "source": [
        "#Wyświetlenie liczby zdjęć w każdym zbiorze\n",
        "train_images_count = sum([len(os.listdir(os.path.join(train_data_folder, class_name))) for class_name in os.listdir(train_data_folder)])\n",
        "val_images_count = sum([len(os.listdir(os.path.join(validation_data_folder, class_name))) for class_name in os.listdir(validation_data_folder)])\n",
        "test_images_count = sum([len(os.listdir(os.path.join(test_data_folder, class_name))) for class_name in os.listdir(test_data_folder)])\n",
        "\n",
        "print(\"Liczba zdjęć w katalogu treningowym: \", train_images_count)\n",
        "print(\"Liczba zdjęć w katalogu walidacyjnym: \", val_images_count)\n",
        "print(\"Liczba zdjęć w katalogu testowym: \", test_images_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfk1OsVPRkRn"
      },
      "outputs": [],
      "source": [
        "# Prezentacja liczebności poszczególnych zbiorów w postaci wykresu słupkowego\n",
        "datasets = ['Zbiór treningowy', 'Zbiór walidacyjny', 'Zbiór testowy']\n",
        "counts = [train_images_count, val_images_count, test_images_count]\n",
        "colors = ['white', 'white', 'white']\n",
        "hatches = ['|', '.', 'x']\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(datasets, counts, color=colors, edgecolor='black', alpha=0.8)\n",
        "\n",
        "for bar, hatch in zip(bars, hatches):\n",
        "    bar.set_hatch(hatch)\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height + 10, str(height), ha='center', fontsize=12)\n",
        "\n",
        "plt.title('Wykres podziału danych', fontsize=16)\n",
        "plt.xlabel('Zbiór danych', fontsize=12)\n",
        "plt.ylabel('Ilość zdjęć', fontsize=12)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoiy3icit-TY"
      },
      "outputs": [],
      "source": [
        "# Stworzenie generatorów dla danych treningowych, walidacyjnych i testowych\n",
        "\n",
        "#Ustalenie reguł wstępnego przetwarzania obrazów\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "     preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "#Utworzenie generatora treningowego i załadowanie danych za pomocą flow_from_directory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_folder,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "#Utworzenie generatora walidacyjnego i załadowanie danych\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_folder,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "#Utworzenie generatora testowego i załadowanie danych\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_folder,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gobneYRp74pS"
      },
      "outputs": [],
      "source": [
        "# Sprawdzenie wymiarów danych\n",
        "for data_batch, labels_batch in train_generator:\n",
        "    print(data_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHWtrDKd89OD"
      },
      "outputs": [],
      "source": [
        "# Wizualizacja 5 przykładowych obrazów po zmodyfikowaniu\n",
        "for data_batch, labels_batch in train_generator:\n",
        "    for i in range(5):  # Wyświetl 5 obrazów\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(data_batch[i].astype('uint8'))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL8Tv5_ItFsU"
      },
      "outputs": [],
      "source": [
        "# Obliczenie wag klas na podstawie liczby przykładów w każdej klasie\n",
        "class_labels = train_generator.classes\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.arange(num_classes),\n",
        "    y=class_labels\n",
        ")\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "print(\"Wagi klas:\", class_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tzl9fLHeDQS"
      },
      "outputs": [],
      "source": [
        "# Wyświetlenie klas z wagami w posortowanej tabeli\n",
        "df_class_weights = pd.DataFrame(list(class_weights_dict.items()), columns=[\"Klasa\", \"Waga\"])\n",
        "df_class_weights_sorted = df_class_weights.sort_values(by=\"Waga\", ascending=False)\n",
        "\n",
        "print(\"Tabela wag klas:\")\n",
        "print(df_class_weights_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS1q71n4iFRr"
      },
      "source": [
        "#Załadowanie modelu ResNet50 z wytrenowanymi wagami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLgh-YLpuBnh"
      },
      "outputs": [],
      "source": [
        "#Załadowanie modelu ResNet50 bez warstwy klasyfikacyjnej i zablokowanie wszystkich jej warstw do dalszego uczenia\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet_model.summary()\n",
        "\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFpGLnh0lYgd"
      },
      "source": [
        "#Utworzenie nowej częsci klasyfikacyjnej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVnUb6L-HTn"
      },
      "outputs": [],
      "source": [
        "#Stworzenie nowej części odpowiedzialnej za klasyfikację z warstwą bazową ResNet50\n",
        "model = Sequential([\n",
        "    resnet_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(120, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z59gnDTH9wRP"
      },
      "outputs": [],
      "source": [
        "#Kompilacja modelu z wykorzystaniem niskiego współczynnika uczenia, aby zachować stabilność wcześniej wytrenowanych wag\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss= CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Konfiguracja funkcji pozwalających na wcześniejsze zatrzymanie treningu, zapisanie najlepszego modelu oraz automatyczne dostosowanie tempa uczenia\n",
        "training_helpers = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint('resnet_frozen_model.keras', monitor='val_accuracy', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6fzQtujl0T5"
      },
      "source": [
        "#Pierwszy etap trenowania modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5U3-AJxnt0Q"
      },
      "outputs": [],
      "source": [
        "#Trenowanie modelu z wykorzystaniem generatorów danych,uwzględniając wagi klas oraz callbacki\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=training_helpers,\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBty7UXm-R3W"
      },
      "outputs": [],
      "source": [
        "#Ocena modelu na zbiorze testowym po pierwszym etapie trenowania\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Wynik na zbiorze testowym - Strata: {test_loss}, Dokładność: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxaugMg_IRad"
      },
      "source": [
        "#Dopracowywanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHW_sr1wI34L"
      },
      "outputs": [],
      "source": [
        "print(\"Architektura modelu przed odblokowaniem warstw do fine-tuningu:\")\n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk4J33P4Jrjk"
      },
      "outputs": [],
      "source": [
        "# Liczba trenowanych parametrów przed odblokowaniem warstw do fine-tuningu\n",
        "trainable_params_before = sum([tf.keras.backend.count_params(w) for w in resnet_model.trainable_weights])\n",
        "print(f\"Liczba trenowanych parametrów przed odblokowaniem warstw do fine-tuningu: {trainable_params_before}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf-RNy4InPS2"
      },
      "source": [
        "Dostosowywaniu wstępnie wytrenowanego modelu do klasyfikacji ras psów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzsIQQKbsnXs"
      },
      "outputs": [],
      "source": [
        "# Odblokowanie wybranych warstw modelu bazowego po pierwszym etapie treningu w celu przeprowadzenia dostrajania\n",
        "# Następnie kompilacja modelu z niższym tempem uczenia, aby uchronić wcześniej wyuczone parametry\n",
        "fine_tune_at = 160\n",
        "\n",
        "for layer in resnet_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "for layer in resnet_model.layers[fine_tune_at:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "print(f\"Liczba wszystkich części w modelu ResNet50: {len(resnet_model.layers)}\")\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA-H1fInIqQ6",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(\"Architektura modelu po odblokowaniu 15 ostatnich warstw:\")\n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdgQxympJyws"
      },
      "outputs": [],
      "source": [
        "# Liczba trenowanych parametrów po odblokowaniu warstw\n",
        "trainable_params_after = sum([tf.keras.backend.count_params(w) for w in resnet_model.trainable_weights])\n",
        "print(f\"Liczba trenowanych parametrów po zablokowaniu warstw: {trainable_params_after}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGkDiRM_I5vD"
      },
      "source": [
        "#Dalsze trenowanie już wcześniej wytrenowanego modelu z odblokowaniem końcowych warstw, aby lepiej dopasować go do rozpoznawania ras psów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qKcQ3PrkZBD"
      },
      "outputs": [],
      "source": [
        "# Dalsze trenowanie modelu przez 20 epok z mniejszym tempem uczenia z wykorzystaniem callbacków do monitorowania procesu\n",
        "fine_tuning_callbacks = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint('resnet_finetuned_model.keras', monitor='val_accuracy', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=fine_tuning_callbacks,\n",
        "    class_weight=class_weights_dict  # Ważenie klas\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dl525sIoUrO"
      },
      "source": [
        "#Ewaluacja i ocena modelu na zbiorze testowym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHgcCWAU-dGm"
      },
      "outputs": [],
      "source": [
        "#Ocena modelu na zbiorze testowym po fine-tuningu\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Wynik na zbiorze testowym po fine-tuningu- Strata: {test_loss}, Dokładność: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XJpKQaJDpB7"
      },
      "outputs": [],
      "source": [
        "#Ocena modelu na zbiorze walidacyjnym\n",
        "val_loss, val_acc = model.evaluate(validation_generator)\n",
        "print(f\"Wynik na zbiorze walidacyjnym po fine-tuningu: {val_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nHdTDE5UKyN"
      },
      "outputs": [],
      "source": [
        "# Wizualizacja dokładności modelu na zbiorze treningowym i walidacyjnym w trakcie treningu\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['accuracy'], linestyle='-', marker='o', color='black', label='Dokładność (trening)')\n",
        "plt.plot(history.history['val_accuracy'], linestyle='--', marker='s', color='black', label='Dokładność (walidacja)')\n",
        "plt.xlabel('Epoka', fontsize=12)\n",
        "plt.ylabel('Dokładność', fontsize=12)\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right', fontsize=10)\n",
        "plt.title('Dokładność treningu i walidacji', fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Wizualizacja straty modelu na zbiorze treningowym i walidacyjnym w trakcie treningu\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'], linestyle='-', marker='o', color='black', label='Strata (trening)')\n",
        "plt.plot(history.history['val_loss'], linestyle='--', marker='s', color='black', label='Strata (walidacja)')\n",
        "plt.xlabel('Epoka', fontsize=12)\n",
        "plt.ylabel('Strata', fontsize=12)\n",
        "plt.legend(loc='upper right', fontsize=10)\n",
        "plt.title('Strata treningu i walidacji', fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjqeMOsKKTWM"
      },
      "outputs": [],
      "source": [
        "#Uzyskanie prognoz modelu na zbiorze testowym i porównanie z rzeczywistymi etykietami\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvTCAr5PPjj6"
      },
      "outputs": [],
      "source": [
        "# Przygotowanie zbioru testowego bez tasowania danych.\n",
        "#Dane testowe są podawane modelowi w tej samej kolejności, co ułatwia porównanie wyników między różnymi sesjami testowania.\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_folder,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Pobranie rzeczywistych etykiet i prognoz\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(f\"Liczba prawdziwych etykiet: {len(true_classes)}\")\n",
        "print(f\"Liczba przewidywanych etykiet:: {len(predicted_classes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEYVnycAKkrm"
      },
      "outputs": [],
      "source": [
        "#Wizualizacja wyników predykcji dla 5 losowych obrazów testowych i porównanie rzeczywistej klasy z przewidywaną przez model\n",
        "filepaths = test_generator.filepaths\n",
        "\n",
        "for i in random.sample(range(len(true_classes)), 5):\n",
        "    img_path = filepaths[i]\n",
        "    img = plt.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Rzeczywista klasa: {class_labels[true_classes[i]]}\\n\"\n",
        "              f\"Przewidziana klasa: {class_labels[predicted_classes[i]]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6FbnXrkJ_on"
      },
      "outputs": [],
      "source": [
        "# Obliczanie dokładności dla każdej klasy na podstawie porównania prawdziwych etykiet z przewidzianymi\n",
        "def compute_class_accuracies(true_classes, predicted_classes, num_classes):\n",
        "    correct_per_class = np.zeros(num_classes)\n",
        "    total_per_class = np.zeros(num_classes)\n",
        "\n",
        "    for i in range(len(true_classes)):\n",
        "        total_per_class[true_classes[i]] += 1\n",
        "        if true_classes[i] == predicted_classes[i]:\n",
        "            correct_per_class[true_classes[i]] += 1\n",
        "\n",
        "    return correct_per_class / total_per_class\n",
        "\n",
        "class_accuracies = compute_class_accuracies(true_classes, predicted_classes, len(class_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSONZCxLELdV"
      },
      "outputs": [],
      "source": [
        "def plot_top_accuracies(class_labels, class_accuracies, top_n=10):\n",
        "    sorted_indices = np.argsort(class_accuracies)[::-1][:top_n]\n",
        "    top_labels = [class_labels[i] for i in sorted_indices]\n",
        "    top_accuracies = class_accuracies[sorted_indices]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    bars = plt.barh(top_labels, top_accuracies, color='white', edgecolor='black', height=0.7)\n",
        "\n",
        "    for bar in bars:\n",
        "        bar.set_hatch('/')  # Kropki\n",
        "\n",
        "    plt.xlabel('Dokładność', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Klasy', fontsize=14, fontweight='bold')\n",
        "    plt.title(f'Top {top_n} klas o największej dokładności', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for i, v in enumerate(top_accuracies):\n",
        "        plt.text(v + 0.02, i, round(v, 2), ha='left', va='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.xlim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "plot_top_accuracies(class_labels, class_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94YzSbWYENu1"
      },
      "outputs": [],
      "source": [
        "def plot_low_accuracies(class_labels, class_accuracies, threshold=0.5):\n",
        "    low_acc_indices = np.where(class_accuracies < threshold)[0]\n",
        "    if len(low_acc_indices) == 0:\n",
        "        print(\"Brak klas z dokładnością poniżej 50%.\")\n",
        "        return\n",
        "\n",
        "    low_labels = [class_labels[i] for i in low_acc_indices]\n",
        "    low_accuracies = class_accuracies[low_acc_indices]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    bars = plt.barh(low_labels, low_accuracies, color='white', edgecolor='black', height=0.7)\n",
        "\n",
        "    for bar in bars:\n",
        "        bar.set_hatch('-')  # Kreski poziome\n",
        "\n",
        "    plt.xlabel('Dokładność', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Klasy', fontsize=14, fontweight='bold')\n",
        "    plt.title('Klasy z dokładnością poniżej 50%', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for i, v in enumerate(low_accuracies):\n",
        "        plt.text(v + 0.02, i, round(v, 2), ha='left', va='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.xlim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "plot_low_accuracies(class_labels, class_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyCXK5inXKSS"
      },
      "outputs": [],
      "source": [
        "# Wizualizacja obrazów dla klasy\n",
        "def plot_images_for_class(class_name, image_directory, title, num_images=9):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    images = os.listdir(os.path.join(image_directory, class_name))\n",
        "    for i in range(min(num_images, len(images))):\n",
        "        img_name = random.choice(images)\n",
        "        img_path = os.path.join(image_directory, class_name, img_name)\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        plt.subplot(3, 3, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_name, fontsize=8)\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title, fontsize=15)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#Wyświetlenie kla z dokładnością < 50% i wizualizacja obrazów z tych klas\n",
        "low_accuracy_classes = [class_labels[i] for i, acc in enumerate(class_accuracies) if acc < 0.5]\n",
        "print(\"Klasy z dokładnością mniejszą niż 50%:\")\n",
        "print(\", \".join(low_accuracy_classes))\n",
        "\n",
        "for cls in low_accuracy_classes:\n",
        "    plot_images_for_class(cls, test_data_folder, f\"Niska dokładność - klasa: {cls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IKYVeoxKHMm"
      },
      "outputs": [],
      "source": [
        "# Wyświetlanie najgorzej przewidywanej klasy i klasy z którą jest najczęściej mylona\n",
        "def display_confusion_details(true_classes, predicted_classes, class_labels):\n",
        "    cm = confusion_matrix(true_classes, predicted_classes)\n",
        "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
        "    worst_class_idx = np.argmin(class_accuracies)\n",
        "    worst_class_name = class_labels[worst_class_idx]\n",
        "    worst_class_accuracy = class_accuracies[worst_class_idx]\n",
        "\n",
        "    cm_without_diagonal = cm[worst_class_idx].copy()\n",
        "    cm_without_diagonal[worst_class_idx] = 0\n",
        "\n",
        "    # Znajdowanie klasy najczęściej mylonej z najgorzej przewidywaną klasą\n",
        "    most_confused_class_idx = np.argmax(cm_without_diagonal)\n",
        "    most_confused_class_name = class_labels[most_confused_class_idx]\n",
        "    most_confused_value = cm[worst_class_idx, most_confused_class_idx]\n",
        "\n",
        "    print(f\"Najgorzej przewidywana klasa: {worst_class_name} (dokładność: {worst_class_accuracy:.2f})\")\n",
        "    print(f\"Klasa najczęściej mylona z '{worst_class_name}': {most_confused_class_name} \"\n",
        "          f\"({most_confused_value} błędnych predykcji)\\n\")\n",
        "\n",
        "    return worst_class_name, most_confused_class_name\n",
        "\n",
        "# Wywołanie funkcji\n",
        "worst_class, most_confused_class = display_confusion_details(true_classes, predicted_classes, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97O4aZM-KLE3"
      },
      "outputs": [],
      "source": [
        "# Wizualizacja obrazów dla klasy najgorzej przewidywanej\n",
        "plot_images_for_class(worst_class, test_data_folder, f\"Najgorzej przewidywana klasa: {worst_class}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m86fe2ChKOyl"
      },
      "outputs": [],
      "source": [
        "#Wizualizacja klasy z którą najgorzej przewidywana klasa jest najczęściej mylona\n",
        "plot_images_for_class(most_confused_class, test_data_folder, f\"Klasa z która jest najczesciej mylona : {most_confused_class}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obliczenie liczby próbek w każdej klasie i wyświetlenie 10 klas z najmniejszą liczbą próbek\n",
        "class_counts = {cls: len(os.listdir(os.path.join(image_directory, cls))) for cls in class_labels}\n",
        "sorted_class_counts = sorted(class_counts.items(), key=lambda x: x[1])\n",
        "\n",
        "min_classes = sorted_class_counts[:10]\n",
        "min_class_labels = [cls for cls, _ in min_classes]\n",
        "min_class_counts = [count for _, count in min_classes]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(min_class_labels, min_class_counts, color='white', edgecolor='black', hatch='/')\n",
        "\n",
        "for bar in bars:\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(int(bar.get_height())),\n",
        "             ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.xlabel('Klasy', fontsize=12)\n",
        "plt.ylabel('Liczba próbek', fontsize=12)\n",
        "plt.title('10 klas z najmniejszą liczbą próbek', fontsize=15)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u9-wXZqsOxjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświetlenie raportu klasyfikacji"
      ],
      "metadata": {
        "id": "DpcML_j3PfzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
      ],
      "metadata": {
        "id": "LJfaXO6BnDfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels, output_dict=True)\n",
        "\n",
        "df_report = pd.DataFrame(report).T\n",
        "df_report = df_report.iloc[:-3]\n",
        "df_sorted = df_report.sort_values(by='f1-score', ascending=False)\n",
        "\n",
        "best_classes = df_sorted.head(5)\n",
        "worst_classes = df_sorted.tail(5)\n",
        "\n",
        "df_display = pd.concat([best_classes, worst_classes])\n",
        "df_display = df_display[['precision', 'recall', 'f1-score', 'support']]\n",
        "\n",
        "print(\"Top 5 najlepszych i najgorszych klas według F1-score\\n\")\n",
        "print(df_display)\n",
        "\n",
        "# Wizualizacja mapy cieplnej\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_display.iloc[:, :-1], annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5, cbar=True)\n",
        "\n",
        "plt.title('Mapa cieplna dokładności dla wybranych klas', fontsize=14, fontweight='bold')\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12, rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0b49uap6GGR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predykcja klas dla nieznanych obrazów**"
      ],
      "metadata": {
        "id": "CPLOxocAOJOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_paths = [\"pudel.jpg\", \"beagle.jpg\", \"yorkbeagle.jpg\", \"Owczarek-niemiecki-kolorowanka.jpg\", \"pies-bernenski.jpg\", \"człowiekpies.jpg\"]\n",
        "\n",
        "# Pętla przez obrazy\n",
        "for img_path in img_paths:\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Predykcja klasy przez model\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_label = class_labels[predicted_class]\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Przewidziana klasa: {predicted_label}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(f\"Obraz: {img_path}\")\n",
        "    print(f\"Przewidziana klasa: {predicted_label}\\n\")"
      ],
      "metadata": {
        "id": "9p2Yy0W2IoH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_HRuxtCKlKB"
      },
      "outputs": [],
      "source": [
        "model.save('model25.12.keras')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}